{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f098b46a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@Goree_JuhssGuns hahaha he ain't even worth my...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @hsaymssik: Sucks to have the smile wiped o...</td>\n",
       "      <td>gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Just a reminder, it's absolutely disgusting to...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @BuzzFeedUK: When you accidentally open you...</td>\n",
       "      <td>other_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Loving the look of the fritters! #mkr</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text   cyberbullying_type\n",
       "0  @Goree_JuhssGuns hahaha he ain't even worth my...            ethnicity\n",
       "1  RT @hsaymssik: Sucks to have the smile wiped o...               gender\n",
       "2  Just a reminder, it's absolutely disgusting to...            ethnicity\n",
       "3  RT @BuzzFeedUK: When you accidentally open you...  other_cyberbullying\n",
       "4              Loving the look of the fritters! #mkr    not_cyberbullying"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"cyberbullying_tweets.csv\")\n",
    "\n",
    "data_shuffled = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Save to a new CSV file (optional)\n",
    "data_shuffled.to_csv(\"cyberbullying_tweets_shuffled.csv\", index=False)\n",
    "data = pd.read_csv(\"cyberbullying_tweets_shuffled.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4d14dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/macbookpro/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@Goree_JuhssGuns hahaha he ain't even worth my...</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>goree juhssguns hahaha even worth tweets dumb ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @hsaymssik: Sucks to have the smile wiped o...</td>\n",
       "      <td>gender</td>\n",
       "      <td>rt hsaymssik sucks smile wiped face huh kat gl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Just a reminder, it's absolutely disgusting to...</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>reminder absolutely disgusting see people woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @BuzzFeedUK: When you accidentally open you...</td>\n",
       "      <td>other_cyberbullying</td>\n",
       "      <td>rt buzzfeeduk accidentally open front camera h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Loving the look of the fritters! #mkr</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>loving look fritters mkr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text   cyberbullying_type  \\\n",
       "0  @Goree_JuhssGuns hahaha he ain't even worth my...            ethnicity   \n",
       "1  RT @hsaymssik: Sucks to have the smile wiped o...               gender   \n",
       "2  Just a reminder, it's absolutely disgusting to...            ethnicity   \n",
       "3  RT @BuzzFeedUK: When you accidentally open you...  other_cyberbullying   \n",
       "4              Loving the look of the fritters! #mkr    not_cyberbullying   \n",
       "\n",
       "                                          clean_text  \n",
       "0  goree juhssguns hahaha even worth tweets dumb ...  \n",
       "1  rt hsaymssik sucks smile wiped face huh kat gl...  \n",
       "2  reminder absolutely disgusting see people woul...  \n",
       "3  rt buzzfeeduk accidentally open front camera h...  \n",
       "4                           loving look fritters mkr  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "corpus = []\n",
    "for tweet in data['tweet_text']:\n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub(r'[^a-zA-Z]', ' ', tweet)\n",
    "    tweet = tweet.split()\n",
    "    tweet = [word for word in tweet if word not in stop_words]\n",
    "    tweet = ' '.join(tweet)\n",
    "    corpus.append(tweet)\n",
    "\n",
    "data['clean_text'] = corpus\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed3bb3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(max_features=20000)\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "Y = data['cyberbullying_type']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4945b107",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfde311",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cb3a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "nb_preds = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acca2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "knn_preds = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e3139b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "lr_preds = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f22244",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*30}\\nModel: Naive Bayes\\n{'='*30}\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, nb_preds))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, nb_preds))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(confusion_matrix(y_test, nb_preds), annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(f\"Confusion Matrix for Naive Bayes\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4193b288",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*30}\\nModel: KNN\\n{'='*30}\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, knn_preds))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, nb_preds))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(confusion_matrix(y_test, knn_preds), annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(f\"Confusion Matrix for KNN\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569480ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*30}\\nModel: Logistic Regressions\\n{'='*30}\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, lr_preds))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, nb_preds))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(confusion_matrix(y_test, lr_preds), annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(f\"Confusion Matrix for Logistic Regressions\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad38778",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample_tweets = [\n",
    "    \"You're so stupid and annoying!\",\n",
    "    \"I hope you have a great day :)\",\n",
    "    \"Go back to where you came from.\",\n",
    "    \"I hate balck people\"]\n",
    "\n",
    "sample_cleaned = []\n",
    "for tweet in sample_tweets:\n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub(r'[^a-zA-Z]', ' ', tweet)\n",
    "    tweet = tweet.split()\n",
    "    tweet = [word for word in tweet if word not in stop_words]\n",
    "    tweet = ' '.join(tweet)\n",
    "    sample_cleaned.append(tweet)\n",
    "\n",
    "sample_vec = cv.transform(sample_cleaned).toarray()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66be7c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = nb.predict(sample_vec)\n",
    "\n",
    "for tweet, pred in zip(sample_tweets, predictions):\n",
    "    print(f\"Tweet: {tweet}\\nPrediction: {pred}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e31d632",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = knn.predict(sample_vec)\n",
    "\n",
    "for tweet, pred in zip(sample_tweets, predictions):\n",
    "    print(f\"Tweet: {tweet}\\nPrediction: {pred}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef542cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr.predict(sample_vec)\n",
    "\n",
    "for tweet, pred in zip(sample_tweets, predictions):\n",
    "    print(f\"Tweet: {tweet}\\nPrediction: {pred}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
